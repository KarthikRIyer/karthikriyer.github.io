<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://karthikriyer.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://karthikriyer.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-05T17:39:17+00:00</updated><id>https://karthikriyer.github.io/feed.xml</id><title type="html">blank</title><subtitle>CS grad student at Texas A&amp;M University </subtitle><entry><title type="html">Hair Simulation with Position Based Dynamics</title><link href="https://karthikriyer.github.io/blog/2023/hair-sim/" rel="alternate" type="text/html" title="Hair Simulation with Position Based Dynamics"/><published>2023-12-11T11:00:00+00:00</published><updated>2023-12-11T11:00:00+00:00</updated><id>https://karthikriyer.github.io/blog/2023/hair-sim</id><content type="html" xml:base="https://karthikriyer.github.io/blog/2023/hair-sim/"><![CDATA[<figure> <iframe src="https://www.youtube.com/embed/944hJg1Kdng" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto" min-width="1000"/> </figure> <h1 id="overview">Overview</h1> <p>The goal of the project was to simulate multiple hair strands based on the paper “<a href="https://matthias-research.github.io/pages/publications/FTLHairFur.pdf">Fast Simulation of Inextensible Hair and Fur</a>” by Müller, et.al. The technique extends Position Based Dynamics and Follow-The-Leader to simulate inextensible strands. In addition, the paper presents a way to handle hair-hair interaction (including friction and hair-hair repulsion) that uses a variant of the technique presented in “<a href="https://graphics.pixar.com/library/Hair/paper.pdf">Volumetric Methods for Simulation and Rendering of Hair</a>” by Petrovic, Henne and Anderson.</p> <h1 id="algorithm-and-results">Algorithm and Results</h1> <h2 id="pbdftl">PBD/FTL</h2> <p>The paper extends FTL (Follow-the-Leader) for dynamic simulation. FTL deals with the behavior of a single strand. This is very similar to simulating an n-pendulum using PBD. With PBD, connected particles are moved towards each other in the inverse proportion of their masses. But to maintain inextensibility, we move only the second particle in each pair along the strand. If interpreted as mving particles in inverse proportion of masses, this results in the first particle having infinite mass, and the second particle having all the energy. This yields strange behavior:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/plain-ftl-compressed-480.webp 480w,/assets/img/plain-ftl-compressed-800.webp 800w,/assets/img/plain-ftl-compressed-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/plain-ftl-compressed.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Static FTL </div> <p>The technique proposed by Müller, et.al. introduces intentional numerical damping to hide the uneven mass distribution inherent to FTL. The steps for dynamic FTL with damping are:</p> <p>\(\mathbf{p} \xleftarrow{} \mathbf{x} \mathbf{+} \mathbf{\Delta} \mathbf{tv} \mathbf{+} \mathbf{\Delta} \mathbf{t^2 f}\) <br/> \(\mathbf{p} \xleftarrow{} \mathbf{solveConstraints(p)}\) <br/> \(\mathbf{d_i = \textbf{correction vector while solving constraints}}\) <br/> \(\mathbf{v_i} \xleftarrow{} \mathbf{\frac{p_i - x_i}{\Delta t}} + s_{damping} \mathbf{\frac{-d_{i+1}}{\Delta t}}\) <br/> \(\mathbf{x} \xleftarrow{} \mathbf{p}\) <br/></p> <p>On implementing this we get a more reasonable strand simulation with a damping factor of 0.9.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dynamic-ftl-480.webp 480w,/assets/img/dynamic-ftl-800.webp 800w,/assets/img/dynamic-ftl-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/dynamic-ftl.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Dynamic FTL </div> <h2 id="hair-hair-interaction">Hair-hair interaction</h2> <p>A hair density voxel is created, and then additionally populated with particle velocities in order to find a weighted average. Averaging the velocity based on voxel density makes the particles close to each other move with similar velocities thereby imitating friction.</p> <p>Voxel density is given by:</p> <p>\(\mathbf{D_{xyz} = \sum^{}_{i} (1 - |P_x^i - x|)(1 - |P_y^i - y|)(1 - |P_z^i - z|)}\) <br/></p> <p>And the average velocity at each point is given by:</p> <p>\(\mathbf{V_{xyz} = \frac{\sum^{}_{i} (1 - |P_x^i - x|)(1 - |P_y^i - y|)(1 - |P_z^i - z|)v^i}{D_{xyz}} }\) <br/> The final particle velocity is updated as follows:</p> <p>\(\mathbf{v \xleftarrow{} (1 - s_{friction} v + s_{friction}v_{grid})}\) <br/></p> <p>In order to implement repulsion, the technique presented by Müller, et.al. uses the above mentioned density voxel by Petrovic, et.al., but updates the velocities in a different way. First the normalized density gradient is computed at each point (\(\mathbf{g = \nabla \rho / \vert\nabla \rho\vert}\)). Then the velocity is updated as follows:</p> <p>\(\mathbf{v \xleftarrow{} v + s_{repulsion}g/\Delta t}\) <br/></p> <p>Collision with static/kinematic objects (in this case, spheres) has been implemented using a penalty force based approach. Generally PBD collisions with static/kinematic objects are implemented by either solving a collision constraint or directly moving the colliding particle to the surface of the object. Since hair is inextensible, this technique yields unusual behaviour. The current workaround is to use a penalty force based technique, where at the beginning of each time-step, for each collision an extra force opposite to the collision vector is added along with a proportionality constant. The downside of this method is that the proportionality constant is empirical. But with some efforts it yields decent results.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/hair-interaction-collision-480.webp 480w,/assets/img/hair-interaction-collision-800.webp 800w,/assets/img/hair-interaction-collision-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/hair-interaction-collision.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Hair-hair interaction and collision with static/kinematic objects </div> <p>Finally I built a scene with the Victor 3d model from from A3, and gave him some hair! First I imported the mesh in blender, separated the scalp vertices and exported it to an obj. I then imported the scalp mesh into my hair simulator, genrated random points within the triangulated scalp mesh, which were then used as roots for the hair. The body mesh is approximated with 5 spheres for collision (one for each, head, nech, left shoulder, right shoulder and chest). Additionally I also added an osscilating wind force field to make things interesting. Here’s the result!</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/victor-hair-480.webp 480w,/assets/img/victor-hair-800.webp 800w,/assets/img/victor-hair-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/victor-hair.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Hair on a character </div> <h2 id="code-repository">Code Repository</h2> <p>GitHub Repo: <a href="https://github.com/KarthikRIyer/HairSim">HairSim</a></p> <h2 id="acknowledgements">Acknowledgements</h2> <ul> <li>The OpenGL boilerplate code has been borrowed from Prof. Sueda’s assignment material and has been modified for OpenGL 4.x.</li> <li>The project is based on the papers: <ul> <li>“<a href="https://matthias-research.github.io/pages/publications/FTLHairFur.pdf">Fast Simulation of Inextensible Hair and Fur</a>” by Müller, et.al.</li> <li>“<a href="https://graphics.pixar.com/library/Hair/paper.pdf">Volumetric Methods for Simulation and Rendering of Hair</a>” by Petrovic, Henne and Anderson</li> </ul> </li> <li><a href="https://github.com/g-truc/glm">GLM</a> and <a href="https://eigen.tuxfamily.org/index.php?title=Main_Page">Eigen</a> were used for vector math</li> <li><a href="https://github.com/oneapi-src/oneTBB">oneTBB</a> was used for multi-threading</li> <li>The <a href="https://s3-us-west-1.amazonaws.com/fti.website.assets/training/FacewareTech_Victor_Maya.zip">Victor 3D Model</a> is from <a href="https://facewaretech.com/learn/free-assets">facewaretech.com</a></li> </ul>]]></content><author><name></name></author><category term="project"/><category term="animation"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">GSoC ‘20 Final Report</title><link href="https://karthikriyer.github.io/blog/2020/gsoc-20-final-report-copy/" rel="alternate" type="text/html" title="GSoC ‘20 Final Report"/><published>2020-08-26T08:00:00+00:00</published><updated>2020-08-26T08:00:00+00:00</updated><id>https://karthikriyer.github.io/blog/2020/gsoc-20-final-report%20copy</id><content type="html" xml:base="https://karthikriyer.github.io/blog/2020/gsoc-20-final-report-copy/"><![CDATA[<p><img src="/assets/images/gsoc.jpg" alt=""/></p> <p>Hey! GSoC’20 is coming to an end and I’m excited to share my experience and talk about what I worked on this time.</p> <p>This year I worked with the Academy Software Foundation on the OpenTimelineIO project. Ever since I heard about ASWF I was looking for an opportunity to get involved. When I saw it in this year’s GSoC orgs list, I knew this was my chance. Working at Pixar is a dream of mine, and contributing to one of their past projects and being able to work with engineers at Pixar, was in a way a dream come true.</p> <p>For those who are not aware about the OpenTimelineIO project, it is an interchange format and a library for use with editorial cut information. In simpler words we can use this format and library to share video editing timelines between different content creation software, and much more! For more information see <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO">this</a>.</p> <p>My proposal for this year’s project had three parts, one of which wasn’t in OTIO’s ideas list.</p> <ul> <li>Add support for all the predicates from Allen’s Interval Algebra for TimeRange.</li> <li>C language bindings</li> <li>Java language bindings (this wasn’t in the ideas list)</li> </ul> <p>OTIO has some core math libraries for working with time, and a restructuring of these libraries around a more consistent mathematical framework has been in planning. The support for <a href="https://en.wikipedia.org/wiki/Allen%27s_interval_algebra">Allen’s Interval Algebra</a> is one of the first changes amongst many to come. I had to add operators to determine relationships between time ranges. For example, to check if two ranges had any intersection, or if one range came before another.</p> <p>OTIO is written in C++. Having it’s functionality in multiple languages is always going to be helpful. It can have use cases in other applications or tools, which might need a different language. In order to bind with languages like Lua, Go or Ruby, first we need to wrap the C++ API in C. This part of the project, although relatively straightforward, taught me a few things. Mainly because I had never written C before.</p> <p>The last leg of GSoC was the most fun for me. I worked on Java bindings. It was the first programming language I learnt and have developed a level of comfort with it over the years. I gained a lot out of working on this part of the project. The reason being that I had to work with two different languages at the same time, but more importantly a large team of advisors came together to help out with it. I received a lot of help from the team in understanding how to work with one language (Java) that had in-built reference counting and garbage collection of objects and another (C++) that didn’t have any of these. I got guidance on idiomatic ways to do specific things in Java and on how to keep the API close to how it would be natively on the platform, while writing bindings. All in all, it’s been a fun and enriching experience.</p> <p>Below is a brief of all the work that was done, prior to and during GSoC, along with future plans.</p> <h3 id="prior-to-gsoc">Prior to GSoC</h3> <p>I worked on the following features/issues:</p> <ul> <li>Implement OTIO to SVG Adapter <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/649">PR #649</a> (open)</li> <li>Indicate Empty track in otioview and display track name <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/677">PR #677</a> (merged)</li> <li>Implement Clip Inspector <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/686">PR #686</a> (open)</li> <li>Toggle ‘complete track name’ display on double click in otioview <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/690">PR #690</a> (merged)</li> </ul> <h3 id="during-gsoc">During GSoC</h3> <ul> <li>Add support for predicates from Allen’s Interval Algebra for TimeRange <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/697">PR #697</a> (merged)</li> <li>Initialize C language bindings <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/696">PR #696</a> (merged)</li> <li>C bindings - wrap safely typed any <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/720">PR #720</a> (merged)</li> <li>Add tests for C-bindings <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/723">PR #723</a> (unmerged and closed)</li> <li>Enforce stricter interval algebra rules for overlaps and contains <a href="Enforce stricter interval algebra rules for overlaps and contains">PR #760</a> (merged)</li> <li>Create Java Bindings <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/753">PR #753</a> (open)</li> <li>Remove redundant test and add comments to tests <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/712">PR #712</a>, <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/723">PR #725</a>, <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/755">PR #755</a>, <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/757">PR #757</a> (merged)</li> <li>Use std::fabs() instead of abs() in rationalTime.cpp <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/721">PR #721</a> (merged)</li> <li>Add .clang-format file <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/707">PR #707</a> (open)</li> <li>Create GitHub Actions Workflow <a href="https://github.com/PixarAnimationStudios/OpenTimelineIO/pull/752">PR #752</a> (open)</li> </ul> <h3 id="future-plans">Future plans</h3> <p>Although I’ve met the goals as planned, there is still some polishing work to be done on the bindings. My mentor Nick Porcino is working with the C-bindings to make it easier to use and making a sample app to demonstrate the library. The Java bindings can be made more feature complete by implementing a few algorithms not present in the C++ core, but in the OTIO python bindings. The Java bindings have been added as a goal for the next beta release, so I need to make it release ready. With the mobile devices becoming cheaper and more powerful, content creation and consumption on phones is increasing. So building and maintaining the Java bindings for Android makes sense. My next goal will be to package it for Android and build a sample app to view OTIO timelines.</p> <h3 id="highlights-and-challenges">Highlights and challenges</h3> <ul> <li><strong>Making sure the TimeRange operators follow the correct rules:</strong> The diagrams found online explaining these rules can be ambiguous. I had to do some legwork and look at existing implementations of these operators elsewhere to make sure I was doing the right thing.</li> <li><strong>Reference counting in the bindings:</strong> It takes some time for beginners to understand how reference counting works in OTIO. It was the same with me. Initially I implemented the C-bindings without taking care of reference counting and had a hard time trying to debug segmentation faults. Nick came to the rescue and found the reason for the crashes and fixed them. Once I’d understood this well I didn’t have much trouble working on the Java bindings.</li> <li><strong>Getting Java and the C++ JNI code to build:</strong> A major amount of time went into figuring out a way to build the native code and the Java code in one go, packaging everything into a JAR archive and using it in other projects. Some part of this was done prior to GSoC and some after the work on Java bindings concluded. Most of it was going through other projects on GitHub, reading Gradle’s documentation and a lot of trial and error. Finally the build works well on all platforms.</li> <li><strong>Garbage collection and freeing native memory in Java bindings:</strong> This was the most confusing part for me in the Java bindings. I wouldn’t have been able to figure out a method to do this without the help from Anton Margoline and Eric Reinecke. We used PhantomReferences to find out when an object was to be garbage collected and freed native memory accordingly. This was a new concept for me and I had fun implementing it.</li> <li><strong>Maintaining the native platform’s feel in the bindings:</strong> It was more of a precaution than a challenge. It included writing some boilerplate code to make everything feel Java-like as much as possible. I picked up a few things in Java-8 along the way, that I hadn’t used before.</li> </ul> <p>It’s been a fun and productive summer and I’m a little sad that it’s my last time being a GSoC candidate. But I’m surely going to stick around as a regular contributor to OTIO and try to get other people involved, maybe mentor future GSoC students!</p> <h3 id="acknowledgements">Acknowledgements</h3> <p>I’d like to thank my mentors and all the others who helped me during these three months. <a href="https://github.com/meshula">Nick Porcino</a> has been in constant contact with me throughout GSoC providing feedback and helping clear doubts on the go. <a href="https://github.com/jminor">Joshua Minor</a>, <a href="https://github.com/ssteinbach">Stephan Steinbach</a> and <a href="https://github.com/reinecke">Eric Reinecke</a> have helped clarify issues with all OTIO work GSoC and non-GSoC, such as explaining the semantics of the TimeRange operators, how timecodes worked and how to get CI working properly. <a href="https://github.com/margant">Anton Margoline</a> and Eric Reinecke provided invaluable guidance with the Java bindings. Last but not the least, <a href="https://github.com/davidbaraff">David Baraff</a> helped me understand how reference counting worked with the python bindings. He was very patient and answered the silliest of doubts.</p>]]></content><author><name></name></author><category term="gsoc"/><category term="gsoc"/><category term="aswf"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">GSoC ‘19 Final Report</title><link href="https://karthikriyer.github.io/blog/2019/gsoc-19-final-report/" rel="alternate" type="text/html" title="GSoC ‘19 Final Report"/><published>2019-08-25T08:00:00+00:00</published><updated>2019-08-25T08:00:00+00:00</updated><id>https://karthikriyer.github.io/blog/2019/gsoc-19-final-report</id><content type="html" xml:base="https://karthikriyer.github.io/blog/2019/gsoc-19-final-report/"><![CDATA[<figure data-orig-width="1800" data-orig-height="699" class="tmblr-full"><img src="https://64.media.tumblr.com/20d49ccec9f989752fbe78eaf910be7d/df7259fd287780c0-99/s540x810/c7780eac61f76bf37e7f8a8ccea85346f9790721.jpg" alt="image" data-orig-width="1800" data-orig-height="699"/></figure> <p>GSoC is coming to an end. I’m glad to say that I’ve met all the goals as planned in the beginning. You can find out about it in my previous blog posts.<br/></p> <p>This post is going to be a very brief report of all the things implemented, goals accomplished, some stuff that’s left to do and future plans.</p> <p>My project was to implement a Data Visualization library in Swift (similar to matplotlib). Before this project, no plotting framework had been written in Swift that could work on Linux, macOS, iOS, or the the other platforms Swift can target. A truly cross-platform Swift plotting framework was needed to fill a gap in the Swift data science ecosystem. </p> <p><b>GitHub link to project: </b><a href="https://github.com/KarthikRIyer/swiftplot">https://github.com/KarthikRIyer/swiftplot</a></p> <figure data-orig-width="960" data-orig-height="540" class="tmblr-full"><img src="https://64.media.tumblr.com/12ae2a935a71abc42c514de8b8d2372a/df7259fd287780c0-71/s540x810/4ca23755472bfb7082fecf4c6ab6107723bc6daf.png" alt="image" data-orig-width="960" data-orig-height="540"/></figure> <p><b>What work was done?</b></p> <p>The following features were implemented:</p> <p>1. LineChart <a href="https://github.com/KarthikRIyer/swiftplot/pull/4">#4</a></p> <p>2. Plotting functions in LineChart <a href="https://github.com/KarthikRIyer/swiftplot/pull/11">#11</a></p> <p>3. SVG Renderer and AGG Renderer as backends. <a href="https://github.com/KarthikRIyer/swiftplot/pull/21">#3</a></p> <p>4. Secondary axis in LineChart. <a href="https://github.com/KarthikRIyer/swiftplot/pull/16">#16</a></p> <p>5. Bar Chart (both vertical and horizontal, with hatching). <a href="https://github.com/KarthikRIyer/swiftplot/pull/21">#21</a> <a href="https://github.com/KarthikRIyer/swiftplot/pull/23">#23</a></p> <p>6. Scatter Plot (with various scatter patterns). <a href="https://github.com/KarthikRIyer/swiftplot/pull/25">#25</a></p> <p>7. Histogram <a href="https://github.com/KarthikRIyer/swiftplot/pull/30">#30</a></p> <p>8. Improved aesthetics and text rendering using FreeType. <a href="https://github.com/KarthikRIyer/swiftplot/pull/33">#33</a></p> <p>9. A set of examples, to make sure addition of code doesn’t break the existing code. (initiated in <a href="https://github.com/KarthikRIyer/swiftplot/pull/7">#7</a> with many updates in subsequent PRs).</p> <p>10. A pure Swift library to generate Jupyter display messages. It is used to display base64 images in a Jupyter notebook. <a href="https://github.com/google/swift-jupyter/pull/67">#67</a></p> <p><b>What’s left to do?</b></p> <p>Although I’ve completed all the goals as planned, I have started work on a CoreGraphics rendering backend for the iOS and macOS platforms. The PR is currently under review, and little work is left before it is ready to be merged. <a href="https://github.com/KarthikRIyer/swiftplot/pull/35">#35</a></p> <p>Also the updated documentation is yet to be merged. This PR has also been submitted for review. <a href="https://github.com/KarthikRIyer/swiftplot/pull/36">#36</a></p> <p>Also, the latest work doesn’t work wih Jupyter Notebooks becuase it isn’t able to find the FreeType install on the system when in Jupyter. I haven’t been able to find a fix for this yet.</p> <p><b>Future Work</b></p> <p>These are some things I plan to work on, post GSoC:</p> <p>1. Implement an OpenGL Rendering backend.</p> <p>2. Work on adding support for real-time plotting. For example updating the plot while a machine learning model is training.</p> <p>3. Implement more complex plot types, such as Contours and Fields.</p> <p><b>Highlights and Challenges</b></p> <ul><li><b>A flexible architecture</b>: This approach was slightly new to me. I had to implement an architecture that kept the rendering of primitives as far away from the plotting logic as possible. This provided the necessary flexibility to add more rendering backends when required.</li><li><b>Implementing a pure Swift display library for swift-jupyter</b>: It took me some time to understand how Jupyter worked. I hadn’t ever used Jupyter notebook before, let alone write a library for it. Once I understood how Jupyter worked it was relatively easy to get it to work. But I still faced a few hurdles which were a little tricky to debug. Like, when I was sending a serialized c-string to the Jupyter kernel, it had a next line delimiter at the end. This caused problems with the Jupyter kernel. I required help from my mentors to solve this issue. I also got to explore SHA256 hashing while working on this. It was necessary for message signing. I used IBM’s BlueCryptor library for SHA256.</li><li><b>Allowing more input data types</b>: Deciding which method to use to allow more input data types was time consuming. In the end we settled on generics. Implementing this also took some time, and it was a bit tricky to get the FloatConvertible protocol to work. FloatConvertible was a Swift protocol I wrote which took Numeric input which could be converted into Float. This isn’t perfect yet. It still has some trouble working with the Int Data type.</li><li><b>Working with FreeType</b>: Working with FreeType was a little tricky. I needed a method to draw custom fonts to improve the aesthetics of the plot. Although AGG provides methods that uses FreeType to draw text, I needed a way to use FreeType with Swift Package Manager. One way was to include FreeType with SwiftPlot, but I couldn’t get it to build with Swift Package Manager. FreeType had it’s own build configuration and also had some Python files. The other option was to make Swift Package Manager find the FreeType install on the system, which came with the necessary headers and the compiled binaries. After a lot of legwork I found a way to do that. The next hurdle here was to test it on the macOS platform. I didn’t have a Mac and when I got access to one I wasn’t able to install FreeType on it. After some more legwork I was able to build FreeType on my own and install it from there. This section is also not perfect yet. It isn’t able to find the FreeType install on the system when in a Jupyter Notebook.</li></ul> <p><b>Conclusion</b></p> <p>I got to learn a lot of things during the summers. I learnt a new language (Swift) and its conventions, approach to building flexible frameworks, how Jupyter works, and many more things. In other words I’ve had a great and productive summer, working under the guidance of the best mentors possible. Brad and Marc (my mentors) were very motivating and their solutions to my problems always worked! </p> <p>It was a great feeling to see my project take shape from scratch and even greater to see the community showing interest in it right from the start. I will definitely keep working on this project post GSoC and would like to see a community growing around it, and people contributing to it.</p> <p>I hope that this project comes to the next GSoC too so that it keeps on maturing and its reach increases more. I would be more than willing to help people get started.</p> <p><br/></p> <p>I’ll keep posting updates whenever there are any developments. So stay tuned!!</p>]]></content><author><name></name></author><category term="gsoc"/><category term="gsoc"/><category term="tensorflow"/><summary type="html"><![CDATA[GSoC is coming to an end. I’m glad to say that I’ve met all the goals as planned in the beginning. You can find out about it in my previous blog posts. This post is going to be a very brief report of all the things implemented, goals accomplished, some stuff that’s left to do and future plans. My project was to implement a Data Visualization library in Swift (similar to matplotlib).]]></summary></entry><entry><title type="html">GSoC Coding Phase - Part 4</title><link href="https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-4/" rel="alternate" type="text/html" title="GSoC Coding Phase - Part 4"/><published>2019-08-18T08:00:00+00:00</published><updated>2019-08-18T08:00:00+00:00</updated><id>https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-4</id><content type="html" xml:base="https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-4/"><![CDATA[<p>Hey everyone!</p> <p>It’s been a long time since I last posted. Since then I’ve passed the second evaluation, and am pretty close to the end of this years’s GSoC. The final evaluation period starts tomorrow.</p> <p>This post will be a very brief account of the developments since the last time, and the future plans.</p> <p>The first topic to address is how we plan to handle data other than Float. After some discussion it was decided that using Generics would be a good option. I wrote a FloatConvertible protocol, and wrote Float and Double extensions conforming to it. The protocol is as shown below:</p> <blockquote><p><i>public protocol FloatConvertible : Comparable{<br/>   init&lt;T: FloatConvertible&gt;(_ x: T)<br/>   init(_ other: Float)<br/>   init(_ other: Double)<br/>   init(_ other: Int)</i></p><p><i>   func toFloat() -&gt; Float<br/>   func toDouble() -&gt; Double<br/>   func toInt() -&gt; Int<br/>   static func +(lhs: Self, rhs: Self) -&gt; Self<br/>   static func -(lhs: Self, rhs: Self) -&gt; Self<br/>   static func *(lhs: Self, rhs: Self) -&gt; Self<br/>   static func /(lhs: Self, rhs: Self) -&gt; Self<br/>}</i></p><p><i>extension Float: FloatConvertible {<br/>   public init&lt;T: FloatConvertible&gt;(_ x: T) {self = x.toFloat()}<br/>   public func toFloat() -&gt; Float {return Float(self)}<br/>   public func toDouble() -&gt; Double {return Double(self)}<br/>   public func toInt() -&gt; Int {return Int(self)}<br/>}</i></p><p><i>extension Double: FloatConvertible {<br/>  public init&lt;T: FloatConvertible&gt;(_ x: T) {self = x.toDouble()}<br/>  public func toFloat() -&gt; Float {return Float(self)}<br/>  public func toDouble() -&gt; Double {return Double(self)}<br/>  public func toInt() -&gt; Int {return Int(self)}<br/>}</i></p></blockquote> <p>Now, each plot class would have generics accepting values conforming to the FloatConvertible protocol. I’m using Floats for calculations at most places. As the input data conforms to FloatConvertible we can convert each value to a Float before any operation. This method also avoids type erasure. Most of you might notice that there’s no extension for the Int data type. That’s because I’m facing some issues with it. Whenever I use Integers I get a fatal error while execution, the reason to which I haven’t been able to figure out yet. So, currently we can use Float and Double.</p> <p>The next issue I came across was when I was testing plotting different values. I had forgotten to consider a case when the range of values was less than 1, i.e. the plot markers had to have decimal values. So what I did was if the range was between 1 and 2, I plotted each marker with an increment of half times the inverse of the range. And when the range was less than 1, each increment was one-tenth of the range. I also rounded the values to two significant digits. This worked well for most cases.</p> <p>Brad pointed out that the current plots weren’t as aesthetically pleasing as those generated by currently existing frameworks. The following needed to be changed:</p> <p>1. Font</p> <p>2. Line Size</p> <p>3. Spacing of numbers from axis hatching</p> <p>4. Enable a grid</p> <p>Changing the line size, spacing and enabling a grid were simple tasks and didn’t take a lot of time. The tricky part was using a custom font. Let’s take a look at the approach used with both AGG and SVG Renderers.</p> <p>AGG provides a way to draw text using custom fonts using the FreeType library. Either we need to include FreeType with SwiftPlot or we need a way so that Swift Package Manager can use a version of FreeType installed on the device. I initially wanted to include FreeType with SwiftPlot, but FreeType has its own build system and it also had a few Python files in its source. So I ruled that out. In order to use the install on the device I needed a module that lets SPM know which library to look for. I found <a href="https://github.com/PureSwift/CFreeType">this</a> C module on github which with a few changes I got working. Then I changed the old text functions to use the FreeType functions provided by AGG. The default font I used was <i>Roboto-Regular</i>. I had two reasons for choosing this font. One, it was very clean and professional looking. Second, this font was available in the Google Fonts API(This came in useful for SVG).</p> <p>I couldn’t find any simple way to use custom fonts in SVG that worked everywhere. The only method I found was to use CSS, which worked only in a browser. Brad said that people would use SVG primarily in a browser so supporting that could be a good beginning. The next problem was how to set a default font in SVG? We couldn’t include the font in the SVG file, and including the ttf file along with the SVG file would be very inconvenient. Here the Google Fonts API came in useful. We just need to specify the font family and it would fetch the font whenever the image was loaded into the browser.</p> <p>This almost concludes my work on aesthetics. The only problem left is to get FreeType to work with Jupyter. Currently, It isn’t able to find the FreeType installed on the system.</p> <figure class="tmblr-full" data-orig-height="660" data-orig-width="1000"><img src="https://64.media.tumblr.com/fb53bffe37850d1e12de4b4e40ca3f6e/4d189dd4a9520cd4-59/s540x810/547eda1e76f1ec5699160e632c0ed7dbfa7f518a.png" data-orig-height="660" data-orig-width="1000"/></figure> <blockquote><p>Histogram with updated font and grid</p></blockquote> <p>Apart from this my main objectives are complete. In the leftover time I have started work on a CoreGraphics Renderer for macOS. This would be a great addition to the library and increase its audience.</p> <p>That’s all for this post. I’ll post an update when I have CoreGraphics working. Stay tuned!</p>]]></content><author><name></name></author><category term="gsoc"/><category term="gsoc"/><category term="tensorflow"/><summary type="html"><![CDATA[Hey everyone! It’s been a long time since I last posted. Since then I’ve passed the second evaluation, and am pretty close to the end of this years’s GSoC. The final evaluation period starts tomorrow. This post will be a very brief account of the developments since the last time, and the future plans. The first topic to address is how we plan to handle data other than Float. After some discussion it was decided that using Generics would be a good option. I wrote a FloatConvertible protocol, and wrote Float and Double extensions conforming to it. The protocol is as shown below: public protocol FloatConvertible : Comparable{   init&lt;T: FloatConvertible&gt;(_ x: T)   init(_ other: Float)   init(_ other: Double)   init(_ other: Int)   func toFloat() -&gt; Float   func toDouble() -&gt; Double   func toInt() -&gt; Int   static func +(lhs: Self, rhs: Self) -&gt; Self   static func -(lhs: Self, rhs: Self) -&gt; Self   static func *(lhs: Self, rhs: Self) -&gt; Self   static func /(lhs: Self, rhs: Self) -&gt; Self}extension Float: FloatConvertible {   public init&lt;T: FloatConvertible&gt;(_ x: T) {self = x.toFloat()}   public func toFloat() -&gt; Float {return Float(self)}   public func toDouble() -&gt; Double {return Double(self)}   public func toInt() -&gt; Int {return Int(self)}}extension Double: FloatConvertible {  public init&lt;T: FloatConvertible&gt;(_ x: T) {self = x.toDouble()}  public func toFloat() -&gt; Float {return Float(self)}  public func toDouble() -&gt; Double {return Double(self)}  public func toInt() -&gt; Int {return Int(self)}} Now, each plot class would have generics accepting values conforming to the FloatConvertible protocol. I’m using Floats for calculations at most places. As the input data conforms to FloatConvertible we can convert each value to a Float before any operation. This method also avoids type erasure. Most of you might notice that there’s no extension for the Int data type. That’s because I’m facing some issues with it. Whenever I use Integers I get a fatal error while execution, the reason to which I haven’t been able to figure out yet. So, currently we can use Float and Double. The next issue I came across was when I was testing plotting different values. I had forgotten to consider a case when the range of values was less than 1, i.e. the plot markers had to have decimal values. So what I did was if the range was between 1 and 2, I plotted each marker with an increment of half times the inverse of the range. And when the range was less than 1, each increment was one-tenth of the range. I also rounded the values to two significant digits. This worked well for most cases. Brad pointed out that the current plots weren’t as aesthetically pleasing as those generated by currently existing frameworks. The following needed to be changed: 1. Font 2. Line Size 3. Spacing of numbers from axis hatching 4. Enable a grid Changing the line size, spacing and enabling a grid were simple tasks and didn’t take a lot of time. The tricky part was using a custom font. Let’s take a look at the approach used with both AGG and SVG Renderers. AGG provides a way to draw text using custom fonts using the FreeType library. Either we need to include FreeType with SwiftPlot or we need a way so that Swift Package Manager can use a version of FreeType installed on the device. I initially wanted to include FreeType with SwiftPlot, but FreeType has its own build system and it also had a few Python files in its source. So I ruled that out. In order to use the install on the device I needed a module that lets SPM know which library to look for. I found this C module on github which with a few changes I got working. Then I changed the old text functions to use the FreeType functions provided by AGG. The default font I used was Roboto-Regular. I had two reasons for choosing this font. One, it was very clean and professional looking. Second, this font was available in the Google Fonts API(This came in useful for SVG). I couldn’t find any simple way to use custom fonts in SVG that worked everywhere. The only method I found was to use CSS, which worked only in a browser. Brad said that people would use SVG primarily in a browser so supporting that could be a good beginning. The next problem was how to set a default font in SVG? We couldn’t include the font in the SVG file, and including the ttf file along with the SVG file would be very inconvenient. Here the Google Fonts API came in useful. We just need to specify the font family and it would fetch the font whenever the image was loaded into the browser. This almost concludes my work on aesthetics. The only problem left is to get FreeType to work with Jupyter. Currently, It isn’t able to find the FreeType installed on the system. Histogram with updated font and grid Apart from this my main objectives are complete. In the leftover time I have started work on a CoreGraphics Renderer for macOS. This would be a great addition to the library and increase its audience. That’s all for this post. I’ll post an update when I have CoreGraphics working. Stay tuned!]]></summary></entry><entry><title type="html">GSoC Coding Phase - Part 3</title><link href="https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-3/" rel="alternate" type="text/html" title="GSoC Coding Phase - Part 3"/><published>2019-07-05T08:00:00+00:00</published><updated>2019-07-05T08:00:00+00:00</updated><id>https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-3</id><content type="html" xml:base="https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-3/"><![CDATA[<p>The next thing to do was to get Jupyter notebooks to display the plots using pure Swift. Currently this was being done using the <a href="https://github.com/google/swift-jupyter/blob/master/EnableIPythonDisplay.swift">EnableIPythonDisplay.swift</a> library bundled with <a href="https://github.com/google/swift-jupyter">swift-jupyter</a>. The image was being passed to a display function after encoding it to the base64 format. The display function then used IPython’s display function along with the image format(i.e. PNG) to generate a display message, which was then sent to the Jupyter Kernel. And voila! The image was displayed!</p> <p>For those who don’t know what a Jupyter Notebook is, quoting the Jupyter Notebook website:</p> <blockquote><p>The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text.<br/></p></blockquote> <p>The way Jupyter displays thing is using messages. A message contains all the data that Jupyter requires to display anything.</p> <p>The general format of a Jupyter message(as mentioned <a href="https://jupyter-client.readthedocs.io/en/stable/messaging.html">here</a>) is :</p> <pre>{
  # The message header contains a pair of unique identifiers for the
  # originating session and the actual message id, in addition to the
  # username for the process that generated the message.  This is useful in
  # collaborative settings where multiple users may be interacting with the
  # same kernel simultaneously, so that frontends can label the various
  # messages in a meaningful way.
  'header' : {
                'msg_id' : str, # typically UUID, must be unique per message
                'username' : str,
                'session' : str, # typically UUID, should be unique per session
                # ISO 8601 timestamp for when the message is created
                'date': str,
                # All recognized message type strings are listed below.
                'msg_type' : str,
                # the message protocol version
                'version' : '5.0',
     },

  # In a chain of messages, the header from the parent is copied so that
  # clients can track where messages come from.
  'parent_header' : dict,

  # Any metadata associated with the message.
  'metadata' : dict,

  # The actual content of the message must be a dict, whose structure
  # depends on the message type.
  'content' : dict,

  # optional: buffers is a list of binary data buffers for implementations
  # that support binary extensions to the protocol.
  'buffers': list,
}</pre> <p>To display images/graphics the message type(msg_type tag in the header) is <i>display_data. </i></p> <p>So what I had to do was, generate such display messages using Swift and send them over to the Jupyter Kernel.</p> <p>Initially I found it pretty difficult to understand how messaging worked in Jupyter, so I had next to no idea about what I had to do. I decided to give it a few days and i finally started to understand what it all was. I made a naive implementation of the message generating code but only to fail. I got some error which seemed like gibberish to me. Even Googling didn’t help me here. Then <a href="https://github.com/marcrasi">Marc</a> came to rescue. In swift-jupyter we send the message to the kernel in a serialized form(a utf8 CString). Marc found that while converting to this form, an extra null terminator was added to it, which created an error with Jupyter. Also in my implementation the message wasn’t an optional. So if a message was empty, it was still getting sent and this caused some errors. So, Marc removed the null terminators and made the message an optional. <br/></p> <p>But just sending messages wasn’t enough. Jupyter also needed message signing. A unique signature was generated for each message which was verified by Jupyter and if successful, only then we could see the result appear in the notebook. All this time we wore working by disabling message signing in Jupyter like this:</p> <blockquote><p><i>jupyter notebook &ndash;Session.key=&lsquo;b&quot;&ldquo;&rsquo;</i><br/></p></blockquote> <p>The signature is the HMAC hex digest of the concatenation of:</p> <ul><li>A shared key (typically the <code>key</code> field of a connection file)</li><li>The serialized header</li><li>The serialized parent header</li><li>The serialized metadata</li><li>The serialized content</li></ul> <p>The hashing function to be used was sha256.</p> <p>The problem that I faced here was, how do I get the HMAC hex digest? Implementing it on my own was out of question, because there was no way to guarantee its security. There are no cryptographic functions in Swift available on Linux. On Mac we could use CommonCrypto. It is an Obj-C library that one could import using bridging headers between Obj-C and Swift. The obstacle here was that using CommmonCrypto wouldn’t make it cross-platform, and also I had no idea of how to use bridging headers with swift-jupyter. </p> <p><a href="https://github.com/BradLarson">Brad</a> suggested that we could use IBM’s <a href="https://github.com/IBM-Swift/BlueCryptor">BlueCryptor</a> library. This was a cross-platform Swift cryptography library. On the Mac platform it used the CommonCrypto module and on Linux it used the libssl-dev package.</p> <p>So to use the pure swift library the user had to install BlueCryptor before, or disable message signing.</p> <p>Using BlueCryptor was pretty straightforward. The exact way to get an HMAC hex digest was given in the documentation. I had a few hiccups doing this initially, because I did not know that the key and data for hashing were to be provided as hex strings. I was using simple strings before and therefore wasn’t getting any results. Also the Swift toolchain I was using had some problems due to which it couldn’t compile BlueCryptor. The only Swift toolchains compatible with swift-jupyter were the S4TF nightly builds, which for some reason didn’t have python3.6 support on that specific day, which was a must for swift-jupyter. So I had to build it myself. This took a lot more time than I expected. </p> <p>After all these hassles, finally I got it working. Yipee!!</p> <p>You can find the implementation here: <a href="https://github.com/google/swift-jupyter/blob/master/EnableJupyterDisplay.swift">EnableJupyterDisplay.swift</a></p> <p>Then I submitted a PR, which was reviewed many times. The comments were mostly about code formatting and style. I still hadn’t gotten used to the Swift style. I did what was asked and the PR was merged. There is still work to be done on this, like supporting more file formats, maybe include audio playback, etc. But all of that can come later. Right now the focus is just on making the data visualization library.</p> <p>When I had taken a break from thinking about messaging in Jupyter I got to wotk on fixing the plot dimensions issue with the AGG Renderer.</p> <p>How the AGG Renderer works is that, on initializing an instance of the renderer creates a buffer that holds all the pixels of the image. One could easily say that to have a custom size, one could pass in the image dimensions in the initializer/constructor of the respective class and allocate a buffer of the required size. But on doing this I got a segmentation fault. On investigating the issue using gdb, I found that the error had to do something with the row_accessor not being able to access a pixel. Essentially we were trying to access a wrong memory location somewhere. But even after going through the code many a times I couldn’t figure out where i was going wrong. The previous implementation had the buffer declared globally. It worked that way, but not when the buffer was part of the class.</p> <p>I decided to dig a bit deeper and tried to find out answers online. There seemed to be no such answers anywhere but, I found an AGG mailing list, that had been inactive for more than two years. I did not have high hopes, but there was no harm in giving it a try. I’ll add the link to the mailing list at the end if anyone would need it in the future.</p> <blockquote><p><i>class Plot{<br/><br/>  public:<br/>    agg::rasterizer_scanline_aa&lt;&gt; m_ras;<br/>    agg::scanline_p8              m_sl_p8;<br/>    agg::line_cap_e roundCap = agg::round_cap;<br/>    renderer_aa ren_aa;<br/>    int pngBufferSize = 0;<br/><br/>    unsigned char* buffer;<br/><br/><br/>    agg::int8u*           m_pattern;<br/>    agg::rendering_buffer m_pattern_rbuf;<br/>    renderer_base_pre rb_pre;<br/><br/>    Plot(float width, float height, float subW, float subH){<br/>      frame_width = width;<br/>      frame_height = height;<br/>      sub_width = subW;<br/>      sub_height = subH;<br/>      buffer = new unsigned char[frame_width*frame_height*3];<br/>      agg::rendering_buffer rbuf = agg::rendering_buffer(buffer,<br/> frame_width, frame_height, -frame_width*3);<br/>      pixfmt pixf = pixfmt(rbuf);<br/>      renderer_base rb = renderer_base(pixf);<br/>      ren_aa = renderer_aa(rb);<br/>      pixfmt_pre pixf_pre(rbuf);<br/>      rb_pre = renderer_base_pre(pixf_pre);<br/>    }</i></p></blockquote> <p>This was the part of the code I was using to initialize the renderer. I sent this snippet to the mailing list. Fortunately someone called Stephan Abmus responded to my mail and pointed out that all the objects required for rendering needed to stay in memory while rendering. I won’t bore you with excessive details but here is a brief summary. I was declaring the pixf and rendering buffer in the constructor and as soon as it went out of scope those declarations went out of memory too and thus we got an error. I am still not sure why making the buffer global worked. Even declaring the buffer and pixf outside the constructor didn’t help. Actually pixf is a <i>typedef</i> for pix_fmt, which holds the format of the pixel to be used in the image, for example RGBA. In fact I couldn’t declare pixf outside the constructor because it didn’t have a default constructor. I had to pass in the rendering buffer while declarinf the pixf object. This meant I couldn’t declare the rendering_buffer outside of the constructor. The only option left was to declare the rendering buffer object and the pixf object inside every function that renderer something onto the image. This method worked!I had finally fixed the bug I was racking my brains on from the first day!</p> <p>The next task to accomplish was to provide a better way to give data input to the plots, than the Point type. I was still trying to think of a way to do that. I had tried out generics but at the time it didn’t seem like a viable method. This topic is still under development and once something is finalized I’ll write about it.</p> <p>The goals for my first milestone were done. </p> <p>On June 28, the results of the 1st evaluation were declared. I had finally passed the first evaluation. But I did know beforehand that I’d be passing the evaluation as I had already spoken about it with Brad and Marc. Both of them had given me positive feedback regarding it.</p> <p>Nonetheless, I’ll describe very briefly what the evaluation was. Both the stuent and the mentors were to fill out an evaluation form. The mentor had to give an evaluation of how well the student had performed, and if he/she should pass or not, and the student had to answer a few questions about their GSoC experience and how well they were able to communicate with the mentors.</p> <p>Phase 1 went pretty smoothly. There were a few ups and downs, but I’ve the got possibly the best mentors ever who guided me through the whole process. I got to know about Swift, it’s coding format and style. I learnt a lot about building frameworks through my mentors’ answers to  my questions. I observes=d how they think about the features to implement and what kind of implementation would be best for both the developer and the end user of the product.</p> <figure data-orig-width="635" data-orig-height="529" class="tmblr-full"><img src="https://64.media.tumblr.com/7886b8c03960dfb83c2d2bca3b637af5/45137486d98ca935-ce/s540x810/d6c52ae2c35f8a5b5607742ad1849108baab17a3.png" alt="image" data-orig-width="635" data-orig-height="529"/></figure> <p>This was the feedback I received from my mentors. It was a really great motivator for me and I want to give my best now more than ever. </p> <p>I hope the rest of the summers stays on to be the great experience I’ve had till now.</p> <p>I’ve worked on implementing Histogram since then, and I also seem to have made some progress on the Data Input front. I’ll talk about any further developments in the next post.</p> <p>See you next time! </p>]]></content><author><name></name></author><category term="gsoc"/><category term="gsoc"/><category term="tensorflow"/><summary type="html"><![CDATA[The next thing to do was to get Jupyter notebooks to display the plots using pure Swift. Currently this was being done using the EnableIPythonDisplay.swift library bundled with swift-jupyter. The image was being passed to a display function after encoding it to the base64 format. The display function then used IPython’s display function along with the image format(i.e. PNG) to generate a display message, which was then sent to the Jupyter Kernel. And voila! The image was displayed! For those who don’t know what a Jupyter Notebook is, quoting the Jupyter Notebook website: The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. The way Jupyter displays thing is using messages. A message contains all the data that Jupyter requires to display anything. The general format of a Jupyter message(as mentioned here) is : {  # The message header contains a pair of unique identifiers for the  # originating session and the actual message id, in addition to the  # username for the process that generated the message.  This is useful in  # collaborative settings where multiple users may be interacting with the  # same kernel simultaneously, so that frontends can label the various  # messages in a meaningful way.  'header' : {                'msg_id' : str, # typically UUID, must be unique per message                'username' : str,                'session' : str, # typically UUID, should be unique per session                # ISO 8601 timestamp for when the message is created                'date': str,                # All recognized message type strings are listed below.                'msg_type' : str,                # the message protocol version                'version' : '5.0',     },]]></summary></entry><entry><title type="html">GSoC Coding Phase - Part 2</title><link href="https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-2/" rel="alternate" type="text/html" title="GSoC Coding Phase - Part 2"/><published>2019-06-24T08:00:00+00:00</published><updated>2019-06-24T08:00:00+00:00</updated><id>https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-2</id><content type="html" xml:base="https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-2/"><![CDATA[<p>Last time we left off at where I’d implemented some code to display plots in a Jupyter notebook. The next task was to get an independent y-axis working in the Line Graph. I looked at other plotting frameworks’ implementation of this feature. What matplotlib did was that it had different kinds of plots added to an axes, ad the axes was then plotted. To get independent axes, it was twinned with one of the axes. For example if you have a primary axis and twin a secondary axis with it, they will be plotted opposite to each other. ggplot required you to explicity set the scale for the secondary axis relative to the primary axis. After some thinking I decide that having a primary and secondary axis with series of data being added to either one of them would be a good options. The scaling would be done automatically of course. But how would you differentiate between a plot on either axis? A simple solution for now could be to make the secondary plot lines dashed, so that’s what I went with. Remember I had told you that setting up the tests in the beginning helped me with a bug? While implementing multiple y axes, I gave negative input points for the first time and noticed that I hadn’t though of this while implementing the logic. I could easily check the difference in old and new plots by using git. If the newly rendered image was different it would show up as updated in git. I had lifted the logic directly from Graph-Kit the android library I’d made and it seems I’d made that mistake there too. So I spent some time rectifying that.</p> <p>The next task was to implement Bar Graph. This seemed like an easy enough task as I distinctly remembered it to be less work even when implementing it in Graph-Kit. Bu this time I didn’t repeat the same mistake as I did with Line graph. Although I did initially lift the logic again I immediately checked for loopholes such as negative coordinates. I had to rewrite some of the code to get that done. Additional features planned for Bar Graph were plot hatching and stacked plots. Hatching is the patterns you fill inside the bars, something like shading the bars. For implementing hatching there were two options. One was to use primitives to generate the patterns. As this would be implemented using primitives everything could be done using Swift. This would make all the renderers support hatching. The other option was to have an enum/list of possible hatching patterns and pass a unique value for each case to the renderer and all the pattern generation will be handled independently by the renderer. This meant that each renderer implementation would need to have some logic to generate the patterns, and maybe some renderers would not have out of the box support for this. The former had some disadvantages. If we generated all the pattersn in Swift using primitives we’d have to handle the edge cases i.e when half of a pattern was inside the rectangle and half of it outside, we’d have to clip it. Then there would also be the logic for drawing the pattern in the bound area of the rectangle. Basically we’d have to reinvent the wheel. Even if this was done, in the case of SVG, a lot of statements to render primitives would be added to the file. This would take a lot of time to parse and therefore delay the final image generation. Both the renderers I was using had the pattern generation feature built right into them. They would easily handle all edge cases and filling the pattern in the required area. So I went with the second option. I just had to implement some logic to generate the shapes to be used in the hatching pattern. The patterns I implemented were forward slash backward slash, hollow circle and grid to name a few. Then I went on to implement stacked bars. This could be used when multiple series of data were to be plotted on the came graph. The next series of data was placed over or below the previous series’ bar depending on whether the data point was positive or negative. There were no specific challenges to this other than the usual debugging one does to get any feature working. The last part left in Bar Graph was to allow horizontal bars too. I just had to switch the x and y values if the graph was to be plotted horizontally.</p> <figure class="tmblr-full" data-orig-height="660" data-orig-width="1000"><img src="https://64.media.tumblr.com/b0f64c6bc270da5ee46262e84fdf1daa/tumblr_inline_ptlel4Z0w81v99f5f_540.png" data-orig-height="660" data-orig-width="1000"/></figure> <p>I went on to implement Scatter Plot. This wasn’t a very difficult task as the logic was pretty much the same as that of Line Graph, the difference being that the line weren’t to be joined by lines and instead be replaced with shapes. I added functions to the renderers to draw triangles and polygons. Generating the points to draw shapes like triangle, hexagon, stars was simple trigonometry and rotation of points. I also added a helper function to rotate points about a center. This wrapped up Scatter Plot.</p> <figure class="tmblr-full" data-orig-height="1000" data-orig-width="1000"><img src="https://64.media.tumblr.com/b355305142e17559bd82fe10d82d0073/tumblr_inline_ptlelofZSR1v99f5f_540.png" data-orig-height="1000" data-orig-width="1000"/></figure> <p>While implementing Bar Graph, the plot had to accept String input also. So I had to add String variables to the Point type. This raised a question. Was the current way of using Point to accept data the correct way? We had to think of other ways to support other data types such as Double, Int, etc. Is generics the right way to proceed? This is a topic that’s currently under discussion. </p> <p>Meanwhile I started work on a python free implementation to display plots in Jupyter Notebooks. I also simultaneously fixed the plot dimensions issue with the AGG Renderer. I’ll discuss this next time, so stay tuned!</p>]]></content><author><name></name></author><category term="gsoc"/><category term="gsoc"/><category term="tensorflow"/><summary type="html"><![CDATA[Last time we left off at where I’d implemented some code to display plots in a Jupyter notebook. The next task was to get an independent y-axis working in the Line Graph. I looked at other plotting frameworks’ implementation of this feature. What matplotlib did was that it had different kinds of plots added to an axes, ad the axes was then plotted. To get independent axes, it was twinned with one of the axes. For example if you have a primary axis and twin a secondary axis with it, they will be plotted opposite to each other. ggplot required you to explicity set the scale for the secondary axis relative to the primary axis. After some thinking I decide that having a primary and secondary axis with series of data being added to either one of them would be a good options. The scaling would be done automatically of course. But how would you differentiate between a plot on either axis? A simple solution for now could be to make the secondary plot lines dashed, so that’s what I went with. Remember I had told you that setting up the tests in the beginning helped me with a bug? While implementing multiple y axes, I gave negative input points for the first time and noticed that I hadn’t though of this while implementing the logic. I could easily check the difference in old and new plots by using git. If the newly rendered image was different it would show up as updated in git. I had lifted the logic directly from Graph-Kit the android library I’d made and it seems I’d made that mistake there too. So I spent some time rectifying that. The next task was to implement Bar Graph. This seemed like an easy enough task as I distinctly remembered it to be less work even when implementing it in Graph-Kit. Bu this time I didn’t repeat the same mistake as I did with Line graph. Although I did initially lift the logic again I immediately checked for loopholes such as negative coordinates. I had to rewrite some of the code to get that done. Additional features planned for Bar Graph were plot hatching and stacked plots. Hatching is the patterns you fill inside the bars, something like shading the bars. For implementing hatching there were two options. One was to use primitives to generate the patterns. As this would be implemented using primitives everything could be done using Swift. This would make all the renderers support hatching. The other option was to have an enum/list of possible hatching patterns and pass a unique value for each case to the renderer and all the pattern generation will be handled independently by the renderer. This meant that each renderer implementation would need to have some logic to generate the patterns, and maybe some renderers would not have out of the box support for this. The former had some disadvantages. If we generated all the pattersn in Swift using primitives we’d have to handle the edge cases i.e when half of a pattern was inside the rectangle and half of it outside, we’d have to clip it. Then there would also be the logic for drawing the pattern in the bound area of the rectangle. Basically we’d have to reinvent the wheel. Even if this was done, in the case of SVG, a lot of statements to render primitives would be added to the file. This would take a lot of time to parse and therefore delay the final image generation. Both the renderers I was using had the pattern generation feature built right into them. They would easily handle all edge cases and filling the pattern in the required area. So I went with the second option. I just had to implement some logic to generate the shapes to be used in the hatching pattern. The patterns I implemented were forward slash backward slash, hollow circle and grid to name a few. Then I went on to implement stacked bars. This could be used when multiple series of data were to be plotted on the came graph. The next series of data was placed over or below the previous series’ bar depending on whether the data point was positive or negative. There were no specific challenges to this other than the usual debugging one does to get any feature working. The last part left in Bar Graph was to allow horizontal bars too. I just had to switch the x and y values if the graph was to be plotted horizontally. I went on to implement Scatter Plot. This wasn’t a very difficult task as the logic was pretty much the same as that of Line Graph, the difference being that the line weren’t to be joined by lines and instead be replaced with shapes. I added functions to the renderers to draw triangles and polygons. Generating the points to draw shapes like triangle, hexagon, stars was simple trigonometry and rotation of points. I also added a helper function to rotate points about a center. This wrapped up Scatter Plot. While implementing Bar Graph, the plot had to accept String input also. So I had to add String variables to the Point type. This raised a question. Was the current way of using Point to accept data the correct way? We had to think of other ways to support other data types such as Double, Int, etc. Is generics the right way to proceed? This is a topic that’s currently under discussion.  Meanwhile I started work on a python free implementation to display plots in Jupyter Notebooks. I also simultaneously fixed the plot dimensions issue with the AGG Renderer. I’ll discuss this next time, so stay tuned!]]></summary></entry><entry><title type="html">GSoC Coding Phase - Part 1</title><link href="https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-1/" rel="alternate" type="text/html" title="GSoC Coding Phase - Part 1"/><published>2019-06-15T08:00:00+00:00</published><updated>2019-06-15T08:00:00+00:00</updated><id>https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-1</id><content type="html" xml:base="https://karthikriyer.github.io/blog/2019/gsoc-coding-phase-part-1/"><![CDATA[<p>Hello everyone! <br/></p> <p>A lot has happened since the GSoC results were declared! I’ve got quite a few things implemented in my project, I’ll be breaking the discussion of the first part of the coding phase into two or three parts. So lets get into it without further ado.</p> <p>According to my proposal <a href="https://github.com/KarthikRIyer/GSoC-proposal/blob/master/TensorFlow%20GSoC%202019%20Proposal.pdf">here</a>, I had one week of community bonding, during which I had to make sure that I had everything I needed to begin with the project, and discuss with the mentors what i should be doing ahead of time. I received a mail from my mentors, Brad and Marc welcoming me to the program. After some discussion it was decided that I should modify my milestones a little bit. Swift for TensorFlow is being used in the Fast.ai course. And there’s a lot of interest in displaying plots in Jupyter notebooks, which is being driven by this. This was to be moved to the first milestone. I have never worked with Jupyter notebooks before let alone editing code that communicated with a Jupyter Kernel. Marc guided me through this. It was decided that for an initial implementation I could use the Swift-Python interoperability to display base64 images in a relatively straightforward manner. Once I implemented some of the planned plots I could work on a pure Swift implementation.</p> <p>One of the most important parts of building a framework is that it functions as expected. There will definitely be many revisions and changes to the code later on. This warranted a need for the presence of some tests included in the project repository. This would help in making sure that new changes did not break the previously working plots. (I am really glad that we decided to include this in the first milestone itself. It helped me find a really important bug! We’ll come to it in later on)</p> <p>I have been a little vague in my proposal about implementation of Sub Plots. For those who don’t know what Sub Plots are, they are multiple graphs included in a single display/image. They can be of any type(Line Graph, Bar Graph, etc.). It was necessary to include Sub Plots in the first milestone itself because each Plot would have to be coded in a way that it could be part of a Sub Plot. Implementing all the plots independently and later adding Sub Plot support would be a lot of extra work! </p> <p>So this is what was decided. In the first milestone I would do the following:</p> <ul><li>Make a simple Line Chart implementation with Sub Plot support.</li><li>Setup tests that saves images.</li><li>Get a base64 encoded PNG and use it in Jupyter notebook. Later work on python free implementation.</li><li>Complete line chart implementation in the leftover time.</li></ul> <p>The rest of the stuff for the first milestone according to my proposal were to be moved to the second milestone.</p> <p>It didn’t take long for me to complete the simple line chart. I used most of the code from the prototype I had made with a few changes.</p> <p>Let’s look briefly at the LineGraph implementation. All the further discussion will be applicable to Linux (I am using Ubuntu 18.04 LTS) unless otherwise specified. </p> <p>The first step was to set up the Swift Package. For absolute beginners, this is how you initialise a Swift Package using the Swift Package manager:</p> <p>Execute this command in the terminal.</p> <pre>swift package init --type library</pre> <p>This will initialise a package that is primarily meant to be a library. If you want a package with an executable as the build product, you can change the type flag to <b>executable</b>.</p> <p>Before implementing the plots I had to set up the renderers because they were the entities that would handle all the image generation. The plan was to have almost no plotting logic in the Renderers. They would just allow you to draw primitives such as Lines, Rectangles, Text, etc.</p> <p>One of the Renderers part of the project is the Anti-Grain Geometry C++ library, developed by the late Maxim Shemanarev. I wrote some code to render simple primitives necessary for a Line Graph. Although Swift Package Manager can compile C++ code, C++ functions aren’t directly accessible from Swift code. So I had to write a bridging C-headers. You can call the C-functions from Swift directly which in turn call the C++ functions. You can find the implementation <a href="https://github.com/KarthikRIyer/swiftplot/tree/master/framework/AGGRenderer">here</a>.</p> <p>One other aim of implementing different rendering backends was to facilitate adding more backends in the future. This required all the Renderers to have some main stuff in common. So I made a Renderer protocol that included the main functions that every Renderer must have. Each Renderer will have to conform to that protocol. </p> <p>The AGGRenderer worked fine apart from one thing. The plot dimensions and and therefore the buffer size were hard coded. This meant that the user couldn’t change the size of the image rendered. This was obviously a big handicap to the end user. But for the moment I decided to focus on implementing the plot and getting the basic structure up and running. I could deal with it later on.</p> <p>The other Renderer I planned to implement was a simple SVGRenderer written in Swift. The implementation is pretty simple and straightforward just like the SVG format. It has a String variable that will describe the image. Whenever you need to draw a primitive you pass the data to the SVGRenderer and it concatenates the relevant tag to the String. In the end the Renderer saves the String into a .svg file. </p> <p>We’re talking about passing the plotting data to the Renderer, but how does that happen? I have defined a Point type which is a struct. It contains two Floats, x and y.  You can pass the plotting data to the Renderer in the form of Point variable, or Point arrays. But the end user need not worry about this. All this will be handled by the Plots. Which brings us to the LineGraph implementation.</p> <p>What I noticed first was that each plot would have to have the support of being a SubPlot. Therefore the renderer would need each image and plot to have separate dimensions in case of a SubPlot.  Lets take an example of two SubPlots stacked horizontally. An easy way to go about it would be to do all the plot calculations of each plot in its own independent co-ordinate system and the shift the origin of each plot as required while drawing it.So what I did was create a Plot protocol with a PlotDimensions type that held the image size and the dimesions of the current plot being rendered, and two offset variables, xOffset and yOffset respectively. In this case the xOffset of the second SubPlot will be a positive number and the yOffset will be zero for both of them. The plot dimensions will be equal divisions of the net image space available to all the Sub Plots. The Renderer will just shift the origin of each SubPlot by (xOffset, yOffset). This did the job. </p> <figure data-orig-width="683" data-orig-height="384" class="tmblr-full"><img src="https://64.media.tumblr.com/888771ab888dfe92b821f668f5c5ccee/tumblr_inline_pt5klasjK61v99f5f_540.png" alt="image" data-orig-width="683" data-orig-height="384"/></figure> <p>The Plot protocol has just one more method called drawGraph(). This was because each Plot had to have the functionality to just draw the plot in memory irrespective of what mode of output(like saving images in case of AGG, or displaying an image in a window in case an OpenGL implementation was written) the used Renderer would have. Also this facilitated drawing each SubPlot separately to the image before generating the final output. </p> <p>Then I took the plotting logic from my prototype and the basic Line Graph was done. </p> <p>The next step was to set up the tests. I created an examples directory with individual executable modules, each demonstrating a single feature. In this directory I made a Reference directory with two separate directories for AGG and SVG renders. So that anyone could run all the tests easily in one go, I made a simple bash script with the commands to run each example like so:</p> <pre>swift run &lt;Executable Example Module Name&gt;</pre> <p>Then came the time to let the users show the plots in a Jupyter Notebook. Initially the way I did this was, save the image as usual using the AGGRenderer, re read it from the disk encode it to base64 in C++ code, and send back the String to Swift code. But there was a better way that my mentors suggested. The library that I was using to encode PNGs, <a href="https://lodev.org/lodepng/">lodepng</a>, allowed you to encode the image in memory and not save it to the disk. I could return a pointer to a buffer with the encoded bytes, to the Swift code and use some functions under Foundation to do the base64 encoding in Swift itself. This could come in handy sometime later if another Renderer could generate images that coudl be encoded to base64. I did the encoding using a function like this:</p> <blockquote><p>public func encodeBase64PNG(pngBufferPointer: UnsafePointer&lt;UInt8&gt;, bufferSize: Int) -&gt; String {<br/>    let pngBuffer : NSData = NSData(bytes: pngBufferPointer, length: bufferSize)<br/>    return pngBuffer.base64EncodedString(options: .lineLength64Characters)<br/>}</p></blockquote> <p>To display the image in Jupyter I added these lines to the EnableIPythonDisplay.swift file in the <a href="https://github.com/google/swift-jupyter">swift-jupyter</a> repository:</p> <blockquote><p>func display(base64EncodedPNG: String) {<br/>  let displayImage = Python.import(&ldquo;IPython.display&rdquo;)<br/>  let codecs = Python.import(&ldquo;codecs&rdquo;)<br/>  let imageData = codecs.decode(Python.bytes(base64EncodedPNG, encoding: &ldquo;utf8&rdquo;), encoding: &ldquo;base64&rdquo;)<br/>  displayImage.Image(data: imageData, format: &ldquo;png&rdquo;).display()<br/>}<br/></p></blockquote> <p>To display the plot the only thing the user has to do is to include this file in their jupyter notebook, get the base64 image from the plot object and pass it to the display function.</p> <p>This completed all the main stuff I had planned for my first milestone well before the deadline. By this time the official coding period hadn’t started yet. The first deadline was June 24 and I had almost a month left. I could cover a lot more stuff in my first milestone itself, so I decided to complete the Line Plot and keep at least the Bar Chart implementation in my first milestone.</p> <p>You can find all the code <a href="https://github.com/KarthikRIyer/swiftplot">here</a>.</p> <p>This post has already gotten pretty long, so I’ll sign off here. I’ll be discussing the rest of my Line Graph implementation, Bar Chart implementation and how setting up the tests beforehand helped me avoid a bug, all in my next post.</p> <p>Stay tuned!</p> <p>PS: Don’t forget to subscribe to the Swift for TensorFlow newsletter to stay up to date with the work being done and the happenings of the S4TF community!</p> <p>Here’s the link: <a href="https://www.s4tfnews.com/">https://www.s4tfnews.com/</a></p> <figure data-orig-width="1354" data-orig-height="602" class="tmblr-full"><img src="https://64.media.tumblr.com/5295b11d11a8158ac4d59d8290e3727a/tumblr_inline_pt5jrhVz7A1v99f5f_540.png" alt="image" data-orig-width="1354" data-orig-height="602"/></figure> <p><br/></p> <p>PPS: Also recently a Swift for TensorFlow Special Interest Group has been announced to help steer the framework. Weekly meetings will be held discussion the progress and plan ahead. Anyone interested can sign up to the mailing list <a href="https://github.com/tensorflow/community/blob/master/sigs/swift/CHARTER.md">here</a>.</p>]]></content><author><name></name></author><category term="gsoc"/><category term="gsoc"/><category term="tensorflow"/><summary type="html"><![CDATA[Hello everyone! A lot has happened since the GSoC results were declared! I’ve got quite a few things implemented in my project, I’ll be breaking the discussion of the first part of the coding phase into two or three parts. So lets get into it without further ado. According to my proposal here, I had one week of community bonding, during which I had to make sure that I had everything I needed to begin with the project, and discuss with the mentors what i should be doing ahead of time. I received a mail from my mentors, Brad and Marc welcoming me to the program. After some discussion it was decided that I should modify my milestones a little bit. Swift for TensorFlow is being used in the Fast.ai course. And there’s a lot of interest in displaying plots in Jupyter notebooks, which is being driven by this. This was to be moved to the first milestone. I have never worked with Jupyter notebooks before let alone editing code that communicated with a Jupyter Kernel. Marc guided me through this. It was decided that for an initial implementation I could use the Swift-Python interoperability to display base64 images in a relatively straightforward manner. Once I implemented some of the planned plots I could work on a pure Swift implementation. One of the most important parts of building a framework is that it functions as expected. There will definitely be many revisions and changes to the code later on. This warranted a need for the presence of some tests included in the project repository. This would help in making sure that new changes did not break the previously working plots. (I am really glad that we decided to include this in the first milestone itself. It helped me find a really important bug! We’ll come to it in later on) I have been a little vague in my proposal about implementation of Sub Plots. For those who don’t know what Sub Plots are, they are multiple graphs included in a single display/image. They can be of any type(Line Graph, Bar Graph, etc.). It was necessary to include Sub Plots in the first milestone itself because each Plot would have to be coded in a way that it could be part of a Sub Plot. Implementing all the plots independently and later adding Sub Plot support would be a lot of extra work! So this is what was decided. In the first milestone I would do the following: Make a simple Line Chart implementation with Sub Plot support.Setup tests that saves images.Get a base64 encoded PNG and use it in Jupyter notebook. Later work on python free implementation.Complete line chart implementation in the leftover time. The rest of the stuff for the first milestone according to my proposal were to be moved to the second milestone. It didn’t take long for me to complete the simple line chart. I used most of the code from the prototype I had made with a few changes. Let’s look briefly at the LineGraph implementation. All the further discussion will be applicable to Linux (I am using Ubuntu 18.04 LTS) unless otherwise specified. The first step was to set up the Swift Package. For absolute beginners, this is how you initialise a Swift Package using the Swift Package manager: Execute this command in the terminal. swift package init --type library This will initialise a package that is primarily meant to be a library. If you want a package with an executable as the build product, you can change the type flag to executable. Before implementing the plots I had to set up the renderers because they were the entities that would handle all the image generation. The plan was to have almost no plotting logic in the Renderers. They would just allow you to draw primitives such as Lines, Rectangles, Text, etc. One of the Renderers part of the project is the Anti-Grain Geometry C++ library, developed by the late Maxim Shemanarev. I wrote some code to render simple primitives necessary for a Line Graph. Although Swift Package Manager can compile C++ code, C++ functions aren’t directly accessible from Swift code. So I had to write a bridging C-headers. You can call the C-functions from Swift directly which in turn call the C++ functions. You can find the implementation here. One other aim of implementing different rendering backends was to facilitate adding more backends in the future. This required all the Renderers to have some main stuff in common. So I made a Renderer protocol that included the main functions that every Renderer must have. Each Renderer will have to conform to that protocol.  The AGGRenderer worked fine apart from one thing. The plot dimensions and and therefore the buffer size were hard coded. This meant that the user couldn’t change the size of the image rendered. This was obviously a big handicap to the end user. But for the moment I decided to focus on implementing the plot and getting the basic structure up and running. I could deal with it later on. The other Renderer I planned to implement was a simple SVGRenderer written in Swift. The implementation is pretty simple and straightforward just like the SVG format. It has a String variable that will describe the image. Whenever you need to draw a primitive you pass the data to the SVGRenderer and it concatenates the relevant tag to the String. In the end the Renderer saves the String into a .svg file.  We’re talking about passing the plotting data to the Renderer, but how does that happen? I have defined a Point type which is a struct. It contains two Floats, x and y.  You can pass the plotting data to the Renderer in the form of Point variable, or Point arrays. But the end user need not worry about this. All this will be handled by the Plots. Which brings us to the LineGraph implementation. What I noticed first was that each plot would have to have the support of being a SubPlot. Therefore the renderer would need each image and plot to have separate dimensions in case of a SubPlot.  Lets take an example of two SubPlots stacked horizontally. An easy way to go about it would be to do all the plot calculations of each plot in its own independent co-ordinate system and the shift the origin of each plot as required while drawing it.So what I did was create a Plot protocol with a PlotDimensions type that held the image size and the dimesions of the current plot being rendered, and two offset variables, xOffset and yOffset respectively. In this case the xOffset of the second SubPlot will be a positive number and the yOffset will be zero for both of them. The plot dimensions will be equal divisions of the net image space available to all the Sub Plots. The Renderer will just shift the origin of each SubPlot by (xOffset, yOffset). This did the job.  The Plot protocol has just one more method called drawGraph(). This was because each Plot had to have the functionality to just draw the plot in memory irrespective of what mode of output(like saving images in case of AGG, or displaying an image in a window in case an OpenGL implementation was written) the used Renderer would have. Also this facilitated drawing each SubPlot separately to the image before generating the final output.  Then I took the plotting logic from my prototype and the basic Line Graph was done.  The next step was to set up the tests. I created an examples directory with individual executable modules, each demonstrating a single feature. In this directory I made a Reference directory with two separate directories for AGG and SVG renders. So that anyone could run all the tests easily in one go, I made a simple bash script with the commands to run each example like so: swift run &lt;Executable Example Module Name&gt; Then came the time to let the users show the plots in a Jupyter Notebook. Initially the way I did this was, save the image as usual using the AGGRenderer, re read it from the disk encode it to base64 in C++ code, and send back the String to Swift code. But there was a better way that my mentors suggested. The library that I was using to encode PNGs, lodepng, allowed you to encode the image in memory and not save it to the disk. I could return a pointer to a buffer with the encoded bytes, to the Swift code and use some functions under Foundation to do the base64 encoding in Swift itself. This could come in handy sometime later if another Renderer could generate images that coudl be encoded to base64. I did the encoding using a function like this: public func encodeBase64PNG(pngBufferPointer: UnsafePointer&lt;UInt8&gt;, bufferSize: Int) -&gt; String {    let pngBuffer : NSData=NSData(bytes: pngBufferPointer, length: bufferSize)    return pngBuffer.base64EncodedString(options: .lineLength64Characters)} To display the image in Jupyter I added these lines to the EnableIPythonDisplay.swift file in the swift-jupyter repository: func display(base64EncodedPNG: String) {  let displayImage=Python.import(&ldquo;IPython.display&rdquo;)  let codecs=Python.import(&ldquo;codecs&rdquo;)  let imageData=codecs.decode(Python.bytes(base64EncodedPNG, encoding: &ldquo;utf8&rdquo;), encoding: &ldquo;base64&rdquo;)  displayImage.Image(data: imageData, format: &ldquo;png&rdquo;).display()} To display the plot the only thing the user has to do is to include this file in their jupyter notebook, get the base64 image from the plot object and pass it to the display function. This completed all the main stuff I had planned for my first milestone well before the deadline. By this time the official coding period hadn’t started yet. The first deadline was June 24 and I had almost a month left. I could cover a lot more stuff in my first milestone itself, so I decided to complete the Line Plot and keep at least the Bar Chart implementation in my first milestone. You can find all the code here. This post has already gotten pretty long, so I’ll sign off here. I’ll be discussing the rest of my Line Graph implementation, Bar Chart implementation and how setting up the tests beforehand helped me avoid a bug, all in my next post. Stay tuned! PS: Don’t forget to subscribe to the Swift for TensorFlow newsletter to stay up to date with the work being done and the happenings of the S4TF community! Here’s the link: https://www.s4tfnews.com/ PPS: Also recently a Swift for TensorFlow Special Interest Group has been announced to help steer the framework. Weekly meetings will be held discussion the progress and plan ahead. Anyone interested can sign up to the mailing list here.]]></summary></entry><entry><title type="html">GSoC with TensorFlow</title><link href="https://karthikriyer.github.io/blog/2019/gsoc-with-tensorflow/" rel="alternate" type="text/html" title="GSoC with TensorFlow"/><published>2019-06-07T08:00:00+00:00</published><updated>2019-06-07T08:00:00+00:00</updated><id>https://karthikriyer.github.io/blog/2019/gsoc-with-tensorflow</id><content type="html" xml:base="https://karthikriyer.github.io/blog/2019/gsoc-with-tensorflow/"><![CDATA[<p>Hello everyone!</p> <p>I’ve been selected as a Google Summer of Code developer under TensorFlow. Yaay! </p> <p>It’s been a long time since the results came out, and I’ve finally got around to writing about it&hellip; so my next few posts will be about my GSoC experience with TensorFlow.</p> <p>Let’s start at the very beginning&hellip;a very good place to start&hellip;</p> <p><b>January 2019</b></p> <p>It was that time of year when everyone was gearing up for GSoC. The organisations for 2019 were to be announced on February 27.  There were many who had already started to contribute to open-source organisations that came to GSoC in the past years, to get a head start. This was the most frustrating experience of my life, because I was having a hard time choosing an organization. I had been exploring computer graphics for the past few months and really wanted to do something in that area&hellip;But which org to choose&hellip;I was also in doubt if the organizations that came last year would come this year or not&hellip;</p> <p><b>February 2019</b></p> <p>Finally on February 27, the list of orgs was out&hellip;I had almost given up, but that day I received a message from a senior at college, that TensorFlow had come to GSoC this year and there was a project that would interest me, something related to Data Visualisation. I was a bit confused if I would be able to contribute or not, considering that TensorFlow was an organisation working in Machine Learning. There was no harm in taking a look at the projects, so I did&hellip;</p> <p>The idea my senior was talking about caught my eye. The idea was:</p> <blockquote><p>A library for data visualization in Swift</p><p>Once data has been cleaned and processed into a standard format, the next step in any data science project is to visualize it. This project aims to provide a Swift library similar to matplotlib. Desired features:</p><p>1. Two-dimensional plots: horizontal and vertical bar chart, histogram, scatterplot, line chart<br/>2. Support for images, contours, and fields<br/>3. Support for detailed subplots, axes, and features<br/>Desired languages: C, C++, Swift</p></blockquote> <p>I immediately decided to apply for this project. I had made a plotting framework for Android before and this seemed to be something similar but way more involved. I’d have to work with Swift, a language I hadn’t worked with before. It included graphics work that I wanted to do and I would be working under the guidance of people from the TensorFlow team! This seemed like a great opportunity to learn something new.</p> <p>It turned to to be exactly that. I enquired about the project and guidelines on the Swift for TensorFlow <a href="https://groups.google.com/a/tensorflow.org/forum/#!forum/swift">mailing list</a>. I got excellent guidance from the project mentors <a href="https://github.com/BradLarson">Brad Larson</a>, <a href="https://github.com/marcrasi">Marc Rasi</a> and other community members. I did some digging on my end, got a prototype working and shared it with the S4TF community. </p> <p><b>March 2019</b></p> <p>Then came the time to work on my proposal. The projects aim was to make a Swift library that works cross-platform. Currently available Swift plotting frameworks worked only on Mac and iOS. So the library had to have multiple rendering backends so that the end user may choose one that worked best on their platform. It was important that I implement at least two rendering backends, so that the library would be architectured in a way that made it simple enough to add more backends later on. After several reviews and revisions from the mentors I finalised <a href="https://github.com/KarthikRIyer/GSoC-proposal/blob/master/TensorFlow%20GSoC%202019%20Proposal.pdf">my proposal</a> and made the submission on March 25.</p> <p>Then next month went into preparing and appearing for my end semester examinations, but GSoC results were always on my mind.</p> <p><b>May 2019</b></p> <p>My exams were over and the results were to be declared in 6 days. </p> <p>On 7 May I received a mail:</p> <figure data-orig-width="611" data-orig-height="576" class="tmblr-full"><img src="https://64.media.tumblr.com/1484e908449399a9260cd72e095034f3/tumblr_inline_psqlzw6cwN1v99f5f_540.png" alt="image" data-orig-width="611" data-orig-height="576"/></figure> <p>Thus began my GSoC journey with TensorFlow.</p> <p>Next time I’ll discuss how I got started with my project and share some brief implementation details. Stay tuned!</p>]]></content><author><name></name></author><category term="gsoc"/><category term="gsoc"/><category term="tensorflow"/><summary type="html"><![CDATA[Hello everyone! I’ve been selected as a Google Summer of Code developer under TensorFlow. Yaay!  It’s been a long time since the results came out, and I’ve finally got around to writing about it&hellip; so my next few posts will be about my GSoC experience with TensorFlow. Let’s start at the very beginning&hellip;a very good place to start&hellip; January 2019 It was that time of year when everyone was gearing up for GSoC. The organisations for 2019 were to be announced on February 27.  There were many who had already started to contribute to open-source organisations that came to GSoC in the past years, to get a head start. This was the most frustrating experience of my life, because I was having a hard time choosing an organization. I had been exploring computer graphics for the past few months and really wanted to do something in that area&hellip;But which org to choose&hellip;I was also in doubt if the organizations that came last year would come this year or not&hellip; February 2019 Finally on February 27, the list of orgs was out&hellip;I had almost given up, but that day I received a message from a senior at college, that TensorFlow had come to GSoC this year and there was a project that would interest me, something related to Data Visualisation. I was a bit confused if I would be able to contribute or not, considering that TensorFlow was an organisation working in Machine Learning. There was no harm in taking a look at the projects, so I did&hellip; The idea my senior was talking about caught my eye. The idea was: A library for data visualization in SwiftOnce data has been cleaned and processed into a standard format, the next step in any data science project is to visualize it. This project aims to provide a Swift library similar to matplotlib. Desired features:1. Two-dimensional plots: horizontal and vertical bar chart, histogram, scatterplot, line chart2. Support for images, contours, and fields3. Support for detailed subplots, axes, and featuresDesired languages: C, C++, Swift I immediately decided to apply for this project. I had made a plotting framework for Android before and this seemed to be something similar but way more involved. I’d have to work with Swift, a language I hadn’t worked with before. It included graphics work that I wanted to do and I would be working under the guidance of people from the TensorFlow team! This seemed like a great opportunity to learn something new. It turned to to be exactly that. I enquired about the project and guidelines on the Swift for TensorFlow mailing list. I got excellent guidance from the project mentors Brad Larson, Marc Rasi and other community members. I did some digging on my end, got a prototype working and shared it with the S4TF community. March 2019 Then came the time to work on my proposal. The projects aim was to make a Swift library that works cross-platform. Currently available Swift plotting frameworks worked only on Mac and iOS. So the library had to have multiple rendering backends so that the end user may choose one that worked best on their platform. It was important that I implement at least two rendering backends, so that the library would be architectured in a way that made it simple enough to add more backends later on. After several reviews and revisions from the mentors I finalised my proposal and made the submission on March 25. Then next month went into preparing and appearing for my end semester examinations, but GSoC results were always on my mind. May 2019 My exams were over and the results were to be declared in 6 days.  On 7 May I received a mail: Thus began my GSoC journey with TensorFlow. Next time I’ll discuss how I got started with my project and share some brief implementation details. Stay tuned!]]></summary></entry></feed>